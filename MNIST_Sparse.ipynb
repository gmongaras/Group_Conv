{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117886d1-e8c1-4418-9d20-a00c090310a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a984e4d1-b388-4eaf-aa30-f69c31d5872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f9f954-7ea8-49c3-ae59-e7b840fe1ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Used to transform the data to a transor\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        # Transform to a tensor\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9ff65-021d-4fc4-9f85-dba43134939e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8f94e5-7771-43d3-90c3-edc610f72477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sparse_Conv(nn.Module):\n",
    "    def __init__(self, inCh, outCh, kernel_size, sub_size, device):\n",
    "        super(Sparse_Conv, self).__init__()\n",
    "        \n",
    "        assert sub_size <= inCh\n",
    "        self.sub_size = sub_size\n",
    "        self.inCh = inCh\n",
    "        self.outCh = outCh\n",
    "        self.kernel_height = kernel_size[0]\n",
    "        self.kernel_width = kernel_size[1]\n",
    "\n",
    "        # Useed for weight initialization. Note that instead of\n",
    "        # using inCh, sub_size is used.\n",
    "        k = 1\n",
    "        for s in kernel_size:\n",
    "            k *= s\n",
    "        k = 1/(sub_size*k)\n",
    "\n",
    "        # Create the weights to be of shape (outCh, 1, inCh, kernel_height, kernel_width)\n",
    "        self.weights = torch.empty(outCh, 1, sub_size, kernel_size[0], kernel_size[1], device=device)\n",
    "\n",
    "        # Create biases of shape (outCh, 1)\n",
    "        self.biases = torch.empty(outCh, 1, device=device)\n",
    "\n",
    "        # Initialize the weights using a uniform distribtuion accoring to k\n",
    "        torch.nn.init.uniform_(self.weights, a=-(k**0.5), b=k**0.5)\n",
    "        torch.nn.init.uniform_(self.biases, a=-(k**0.5), b=k**0.5)\n",
    "\n",
    "        # Register the weights as parameters\n",
    "        self.weights = nn.Parameter(self.weights)\n",
    "        self.biases = nn.Parameter(self.biases)\n",
    "        \n",
    "        # self.convs = nn.ParameterList([nn.Conv2d(self.sub_size, 1, kernel_size) for i in range(0, outCh)])\n",
    "        # self.weights = torch.stack([i.weight.clone().to(device) for i in self.convs])\n",
    "        # self.biases = torch.stack([i.bias.clone().to(device) for i in self.convs])\n",
    "        # del self.convs\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if len(X.shape) == 3:\n",
    "            X = X.unsqueeze(0)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # Get the h/W output\n",
    "        h = X.shape[-2] - self.kernel_height\n",
    "        if self.kernel_height % 2 != 0:\n",
    "            h += 1\n",
    "        w = X.shape[-1] - self.kernel_width\n",
    "        if self.kernel_width % 2 != 0:\n",
    "            w += 1\n",
    "            \n",
    "            \n",
    "            \n",
    "        # Number of desired channels\n",
    "        desired_channels = self.outCh+self.sub_size-1\n",
    "        # Number of times to repeat the tensor to get to that goal\n",
    "        num_repeats = math.ceil(desired_channels/self.inCh)\n",
    "        # Repeat the image num_repeats times along the channels\n",
    "        X = X.repeat(1, num_repeats, 1, 1)\n",
    "        # Slice the rest off that we don't need\n",
    "        X = X[:, :desired_channels]\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "        # Pad the image by sub_size-1 along the channels to become (N, C+sub_size-1, L, W)\n",
    "        # X = torch.nn.functional.pad(input=X.unsqueeze(0), pad=(0,0,0,0,0,self.sub_size-1), mode=\"circular\").squeeze(0)\n",
    "        \n",
    "        # Unfold image (batch_size, channels+sub_size-1, windows, kernel_height, kernel_width)\n",
    "        X = X.unfold(2, self.kernel_height, 1).unfold(3, self.kernel_width, 1)\n",
    "        X = X.contiguous().view(X.shape[0], X.shape[1], -1, self.kernel_height, self.kernel_width)\n",
    "\n",
    "        # Let's unfold this tensor to be of shape (batch_size, outCh, windows, kernel_height, kernel_width, sub_size)\n",
    "        X = X.unfold(1, self.sub_size, 1)\n",
    "\n",
    "        # Make tensor of shape (batch_size, windows, outCh, sub_size, kernel_height, kernel_width)\n",
    "        X = X.permute(0, 2, 1, 5, 3, 4)\n",
    "\n",
    "        # Multiply the patches with the weights in order to calculate the conv (batch_size, outCh, HW)\n",
    "        X = (X * self.weights.transpose(0, 1).unsqueeze(0)).sum([3, 4, 5]).permute(0, 2, 1)\n",
    "        \n",
    "        # Add the biases\n",
    "        X += self.biases.unsqueeze(0)\n",
    "\n",
    "        # Reshape to output shape (batch_size, outCh, H, W)\n",
    "        return X.reshape(X.shape[0], -1, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1d8e3-34c1-4d70-a301-89864534f0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775b9cb-dcb7-48eb-8efa-6bc9cebe6490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511561f-f276-4d22-92b5-688f26d0aa49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264802f-4b72-4a52-89b2-5acca27b58a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f57369a-9599-4d67-89c1-e57a174bbbff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in MNIST\n",
    "MNIST_dataset = torchvision.datasets.MNIST(\"./\", train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca09de69-c08a-4387-babf-6eee0551dda7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Used to load in the dataset\n",
    "data_loader = DataLoader(MNIST_dataset, batch_size=256,\n",
    "        pin_memory=True, num_workers=1, \n",
    "        drop_last=False, shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4e571be-f29e-4bd4-b68d-2cf5c8640126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model with 1x28x28 input and 10 output\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # convolution layers\n",
    "        self.convs = nn.Sequential( # 1x28x28\n",
    "            Sparse_Conv(1, 32, (5, 5), 1, device), # 32x24x24\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            Sparse_Conv(32, 32, (5, 5), 8, device), # 32x20x20\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 64x10x10\n",
    "            \n",
    "            Sparse_Conv(32, 64, (5, 5), 8, device), # 64x6x6\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 64x3x3\n",
    "            \n",
    "            nn.Flatten(1, -1), # 3*3*64\n",
    "            nn.Linear(3*3*64, 256), # 256\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10), # 10\n",
    "            nn.LogSoftmax(-1)\n",
    "        ).to(device)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.convs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b863eb67-e3b8-4522-8e70-6629fc604235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aab1a05-cfd8-4430-beb0-9b22eef3bde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optim = torch.optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e62526e0-6c3a-42b9-879d-693d78bd642b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_funct = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97c7a5e2-11a5-4983-9600-a2557cf71dea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.1589794009923935\n",
      "Epoch 1: 0.1623678058385849\n",
      "Epoch 2: 0.030596233904361725\n",
      "Epoch 3: 0.025186046957969666\n",
      "Epoch 4: 0.10473691672086716\n",
      "Epoch 5: 0.07423204928636551\n",
      "Epoch 6: 0.004613690078258514\n",
      "Epoch 7: 0.01740514673292637\n",
      "Epoch 8: 0.04154275730252266\n",
      "Epoch 9: 0.011645420454442501\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 10\n",
    "steps = 0\n",
    "for epoch in range(0, epochs):\n",
    "    # Iterate over all data\n",
    "    for X,labels in data_loader:\n",
    "        # Send the data through the model\n",
    "        y_hat = model(X.to(device))\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_funct(y_hat, labels.to(device))\n",
    "        \n",
    "        # Backprop the loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        steps += 1\n",
    "    print(f\"Epoch {epoch}: {loss.detach().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e27775-8cb5-4715-b692-0918c60f7e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
