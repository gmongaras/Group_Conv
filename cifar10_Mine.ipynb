{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_s0Nbg9DpAPc"
   },
   "source": [
    "# **CIFAR 10**\n",
    "A FFNN (Feed Forward Neural Network) and CNN (Convolutional Nerual Network) have been modeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ke-h5JrjpAPd"
   },
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zW9xz9z8pAPd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from Group_Conv import Group_Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5MKXP4opAPg"
   },
   "source": [
    "## Defining our Transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65p8aqnmpAPh"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Normalize the test set same as training set without augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnxkdKJQpAPj"
   },
   "source": [
    "## Gathering the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "c5a152f3d9ee4397b91c1d9d8880cce8",
      "7255336faada45d6a1aaf77538d483e9",
      "23fd5f5cb146440ebc6d00dbedbd3bcb",
      "0f7b0e50ddcb4f36a54d74c6f7178d16",
      "020910d477cc485eab87891ed80cd098",
      "b7a363934b50404e821275e833e85d13",
      "7b0ac9d19ddc4c438e82bcae91983d90",
      "b2a29e0cdc684ab6b07a473184b16818"
     ]
    },
    "colab_type": "code",
    "id": "gYf2gVENpAPj",
    "outputId": "b76c5692-09b6-49c7-c7ac-f8dca02a14fa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data=datasets.CIFAR10('data/CIFAR10',train=True,download=True,transform=transform_train)\n",
    "test_data=datasets.CIFAR10('data/CIFAR10',train=False,download=True,transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aK6D4DHNpAPm"
   },
   "source": [
    "## Defining our Train, Valid and Test Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eP9ygMwopAPm"
   },
   "outputs": [],
   "source": [
    "num_workers=0\n",
    "batch_size=50\n",
    "valid_size=0.2\n",
    "train_length = len(train_data)\n",
    "indices=list(range(len(train_data)))\n",
    "split = int(np.floor(valid_size * train_length))\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx=indices[split:]\n",
    "valid_idx=indices[:split]\n",
    "\n",
    "train_sampler=SubsetRandomSampler(train_idx)\n",
    "validation_sampler=SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader=DataLoader(train_data,num_workers=num_workers,batch_size=batch_size,sampler=train_sampler)\n",
    "valid_loader=DataLoader(train_data,num_workers=num_workers,batch_size=batch_size,sampler=validation_sampler)\n",
    "test_loader=DataLoader(test_data,shuffle=True,num_workers=num_workers,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "um8SlBWJpAPv"
   },
   "source": [
    "## Defining our Neural Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EbQg9ZOpAPv"
   },
   "outputs": [],
   "source": [
    "class FNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNet,self).__init__()\n",
    "        self.fc1=nn.Linear(3*32*32,2048)\n",
    "        self.fc2=nn.Linear(2048,1024)\n",
    "        self.fc3=nn.Linear(1024,512)\n",
    "        self.fc4=nn.Linear(512,256)\n",
    "        self.out=nn.Linear(256,10)\n",
    "        self.dropout=nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=x.view(-1,32*32*3)\n",
    "        x=self.dropout(F.relu(self.fc1(x)))\n",
    "        x=self.dropout(F.relu(self.fc2(x)))\n",
    "        x=self.dropout(F.relu(self.fc3(x)))\n",
    "        x=self.dropout(F.relu(self.fc4(x)))\n",
    "        x=self.out(x)\n",
    "        return x\n",
    "\n",
    "class convNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convNet,self).__init__()\n",
    "        self.conv1=Group_Conv(3,16,3,sub_size=3,padding=1,device=device)\n",
    "        self.conv2=Group_Conv(16,32,3,sub_size=8,padding=1,device=device)\n",
    "        self.conv3=Group_Conv(32,64,3,sub_size=8,padding=1,device=device)\n",
    "        self.conv4=Group_Conv(64,128,3,sub_size=16,padding=1,device=device)\n",
    "        self.conv5=Group_Conv(128,256,3,sub_size=32,padding=1,device=device)\n",
    "        self.b1=nn.BatchNorm2d(16)\n",
    "        self.b2=nn.BatchNorm2d(64)\n",
    "        self.b3=nn.BatchNorm2d(256)\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2,stride=2)  \n",
    "\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "        self.fc1=nn.Linear(256,128)\n",
    "        self.fc2=nn.Linear(128,64)\n",
    "        self.out=nn.Linear(64,10)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.b1(self.conv1(x))))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(F.relu(self.b2(self.conv3(x))))\n",
    "        x=self.pool(F.relu(self.conv4(x)))\n",
    "        x=self.pool(F.relu(self.b3(self.conv5(x))))\n",
    "        x=x.view(-1,256)\n",
    "        x = self.dropout(x)\n",
    "        x=self.dropout(F.relu(self.fc1(x)))\n",
    "        x=self.dropout(F.relu(self.fc2(x)))\n",
    "        x=self.out(x)   \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "GRtS6QygpAPx",
    "outputId": "53449d3d-acd4-43f1-ad53-e95ed4515be2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNet(\n",
      "  (fc1): Linear(in_features=3072, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc4): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      " convNet(\n",
      "  (conv1): Group_Conv()\n",
      "  (conv2): Group_Conv()\n",
      "  (conv3): Group_Conv()\n",
      "  (conv4): Group_Conv()\n",
      "  (conv5): Group_Conv()\n",
      "  (b1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ") \n",
      " On GPU :  True\n"
     ]
    }
   ],
   "source": [
    "def weight_init_normal(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find('Linear')!=-1:\n",
    "        n = m.in_features\n",
    "        y = (1.0/np.sqrt(n))\n",
    "        m.weight.data.normal_(0, y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "model_1=FNet()\n",
    "model_2=convNet()\n",
    "model_1.apply(weight_init_normal),model_2.apply(weight_init_normal)\n",
    "use_cuda=True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    model_1.cuda()\n",
    "    model_2.cuda()\n",
    "print(model_1,'\\n\\n\\n\\n',model_2,'\\n','On GPU : ',use_cuda and torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsvJRKKXpAPy"
   },
   "source": [
    "## Defining our Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44gNRwTcpAPz"
   },
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zdQy3hgxpAP0"
   },
   "source": [
    "## Training and Validation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9p34jICpAP1"
   },
   "outputs": [],
   "source": [
    "def trainNet(model,lr,trainer,validater):\n",
    "    optimizer=torch.optim.SGD(model.parameters(),lr=lr,momentum=0.9)\n",
    "\n",
    "\n",
    "    # Number of epochs to train for\n",
    "    loss_keeper={'train':[],'valid':[]}\n",
    "    acc_keeper={'train':[],'valid':[]}\n",
    "    train_class_correct = list(0. for i in range(10))\n",
    "    valid_class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    epochs=50\n",
    "\n",
    "    # minimum validation loss ----- set initial minimum to infinity\n",
    "    valid_loss_min = np.Inf \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss=0.0\n",
    "        valid_loss=0.0\n",
    "        train_correct=0.0\n",
    "        valid_correct=0.0\n",
    "        \"\"\"\n",
    "        TRAINING PHASE\n",
    "        \"\"\"\n",
    "        model.train() # TURN ON DROPOUT for training\n",
    "        for images,labels in trainer:\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                images,labels=images.cuda(),labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output=model(images)\n",
    "            loss=criterion(output,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "            _, pred = torch.max(output, 1)\n",
    "            train_correct=np.squeeze(pred.eq(labels.data.view_as(pred)))\n",
    "            for idx in range(batch_size):\n",
    "                label = labels[idx]\n",
    "                train_class_correct[label] += train_correct[idx].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "        \"\"\"\n",
    "        VALIDATION PHASE\n",
    "        \"\"\"\n",
    "        model.eval() # TURN OFF DROPOUT for validation\n",
    "        for images,labels in validater:\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                images,labels=images.cuda(),labels.cuda()\n",
    "            output=model(images)\n",
    "            loss=criterion(output,labels)\n",
    "            valid_loss+=loss.item()\n",
    "            _, pred = torch.max(output, 1)\n",
    "            valid_correct=np.squeeze(pred.eq(labels.data.view_as(pred)))\n",
    "            for idx in range(batch_size):\n",
    "                label = labels[idx]\n",
    "                valid_class_correct[label] += valid_correct[idx].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "        # Calculating loss over entire batch size for every epoch\n",
    "        train_loss = train_loss/len(trainer)\n",
    "        valid_loss = valid_loss/len(validater)\n",
    "\n",
    "        # Calculating loss over entire batch size for every epoch\n",
    "        train_acc=float(100. * np.sum(train_class_correct) / np.sum(class_total))\n",
    "        valid_acc=float(100. * np.sum(valid_class_correct) / np.sum(class_total))\n",
    "\n",
    "        # saving loss values\n",
    "        loss_keeper['train'].append(train_loss)\n",
    "        loss_keeper['valid'].append(valid_loss)\n",
    "\n",
    "        # saving acc values\n",
    "        acc_keeper['train'].append(train_acc)\n",
    "        acc_keeper['valid'].append(valid_acc)\n",
    "\n",
    "        print(f\"Epoch : {epoch+1}\")\n",
    "        print(f\"Training Loss : {train_loss}\\tValidation Loss : {valid_loss}\")\n",
    "\n",
    "        if valid_loss<=valid_loss_min:\n",
    "            print(f\"Validation loss decreased from : {valid_loss_min} ----> {valid_loss} ----> Saving Model.......\")\n",
    "            z=type(model).__name__\n",
    "            torch.save(model.state_dict(), z+'_model.pth')\n",
    "            valid_loss_min=valid_loss\n",
    "\n",
    "        print(f\"Training Accuracy : {train_acc}\\tValidation Accuracy : {valid_acc}\\n\\n\")\n",
    "\n",
    "    return(loss_keeper,acc_keeper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tbJAYRJcpAP6",
    "outputId": "a8a64ea4-c088-428b-8e7f-54dca0ce82a0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Training Loss : 1.6016394989192486\tValidation Loss : 1.3972447124123573\n",
      "Validation loss decreased from : inf ----> 1.3972447124123573 ----> Saving Model.......\n",
      "Training Accuracy : 32.914\tValidation Accuracy : 9.688\n",
      "\n",
      "\n",
      "Epoch : 2\n",
      "Training Loss : 1.2973366347700357\tValidation Loss : 1.180749258697033\n",
      "Validation loss decreased from : 1.3972447124123573 ----> 1.180749258697033 ----> Saving Model.......\n",
      "Training Accuracy : 37.934\tValidation Accuracy : 10.622\n",
      "\n",
      "\n",
      "Epoch : 3\n",
      "Training Loss : 1.1506666284054519\tValidation Loss : 1.1120468747615815\n",
      "Validation loss decreased from : 1.180749258697033 ----> 1.1120468747615815 ----> Saving Model.......\n",
      "Training Accuracy : 41.078\tValidation Accuracy : 11.116\n",
      "\n",
      "\n",
      "Epoch : 4\n",
      "Training Loss : 1.0771428833156824\tValidation Loss : 1.008875523507595\n",
      "Validation loss decreased from : 1.1120468747615815 ----> 1.008875523507595 ----> Saving Model.......\n",
      "Training Accuracy : 43.2235\tValidation Accuracy : 11.555\n",
      "\n",
      "\n",
      "Epoch : 5\n",
      "Training Loss : 1.012962466776371\tValidation Loss : 1.095140024125576\n",
      "Training Accuracy : 44.9208\tValidation Accuracy : 11.7192\n",
      "\n",
      "\n",
      "Epoch : 6\n",
      "Training Loss : 0.9612219043076038\tValidation Loss : 0.9675480884313583\n",
      "Validation loss decreased from : 1.008875523507595 ----> 0.9675480884313583 ----> Saving Model.......\n",
      "Training Accuracy : 46.32033333333333\tValidation Accuracy : 11.976\n",
      "\n",
      "\n",
      "Epoch : 7\n",
      "Training Loss : 0.923065694347024\tValidation Loss : 0.8717112129926682\n",
      "Validation loss decreased from : 0.9675480884313583 ----> 0.8717112129926682 ----> Saving Model.......\n",
      "Training Accuracy : 47.466857142857144\tValidation Accuracy : 12.257142857142858\n",
      "\n",
      "\n",
      "Epoch : 8\n",
      "Training Loss : 0.8921630267426371\tValidation Loss : 0.8972968289256096\n",
      "Training Accuracy : 48.432\tValidation Accuracy : 12.43975\n",
      "\n",
      "\n",
      "Epoch : 9\n",
      "Training Loss : 0.8645203471928835\tValidation Loss : 0.8666329799592495\n",
      "Validation loss decreased from : 0.8717112129926682 ----> 0.8666329799592495 ----> Saving Model.......\n",
      "Training Accuracy : 49.258\tValidation Accuracy : 12.62888888888889\n",
      "\n",
      "\n",
      "Epoch : 10\n",
      "Training Loss : 0.8415744279697538\tValidation Loss : 0.8249816858768463\n",
      "Validation loss decreased from : 0.8666329799592495 ----> 0.8249816858768463 ----> Saving Model.......\n",
      "Training Accuracy : 49.9822\tValidation Accuracy : 12.789\n",
      "\n",
      "\n",
      "Epoch : 11\n",
      "Training Loss : 0.8181573275849223\tValidation Loss : 0.9439120753109456\n",
      "Training Accuracy : 50.62836363636364\tValidation Accuracy : 12.859454545454545\n",
      "\n",
      "\n",
      "Epoch : 12\n",
      "Training Loss : 0.7999876022338868\tValidation Loss : 0.7973375755548477\n",
      "Validation loss decreased from : 0.8249816858768463 ----> 0.7973375755548477 ----> Saving Model.......\n",
      "Training Accuracy : 51.22083333333333\tValidation Accuracy : 12.987833333333333\n",
      "\n",
      "\n",
      "Epoch : 13\n",
      "Training Loss : 0.7824867795035243\tValidation Loss : 0.829823457300663\n",
      "Training Accuracy : 51.75676923076923\tValidation Accuracy : 13.088153846153846\n",
      "\n",
      "\n",
      "Epoch : 14\n",
      "Training Loss : 0.7699077215045691\tValidation Loss : 0.7996333679556846\n",
      "Training Accuracy : 52.241571428571426\tValidation Accuracy : 13.193142857142858\n",
      "\n",
      "\n",
      "Epoch : 15\n",
      "Training Loss : 0.750845603607595\tValidation Loss : 0.7734339602291584\n",
      "Validation loss decreased from : 0.7973375755548477 ----> 0.7734339602291584 ----> Saving Model.......\n",
      "Training Accuracy : 52.709066666666665\tValidation Accuracy : 13.284666666666666\n",
      "\n",
      "\n",
      "Epoch : 16\n",
      "Training Loss : 0.7382995785027743\tValidation Loss : 0.7630908900499344\n",
      "Validation loss decreased from : 0.7734339602291584 ----> 0.7630908900499344 ----> Saving Model.......\n",
      "Training Accuracy : 53.14975\tValidation Accuracy : 13.369625\n",
      "\n",
      "\n",
      "Epoch : 17\n",
      "Training Loss : 0.7306731389462948\tValidation Loss : 0.7573522941768169\n",
      "Validation loss decreased from : 0.7630908900499344 ----> 0.7573522941768169 ----> Saving Model.......\n",
      "Training Accuracy : 53.54611764705882\tValidation Accuracy : 13.450470588235294\n",
      "\n",
      "\n",
      "Epoch : 18\n",
      "Training Loss : 0.7165917980670929\tValidation Loss : 0.7921512681245804\n",
      "Training Accuracy : 53.916666666666664\tValidation Accuracy : 13.513\n",
      "\n",
      "\n",
      "Epoch : 19\n",
      "Training Loss : 0.7023960214108229\tValidation Loss : 0.7478326243162156\n",
      "Validation loss decreased from : 0.7573522941768169 ----> 0.7478326243162156 ----> Saving Model.......\n",
      "Training Accuracy : 54.25526315789474\tValidation Accuracy : 13.578736842105263\n",
      "\n",
      "\n",
      "Epoch : 20\n",
      "Training Loss : 0.695787606947124\tValidation Loss : 0.7523795907199383\n",
      "Training Accuracy : 54.5805\tValidation Accuracy : 13.6427\n",
      "\n",
      "\n",
      "Epoch : 21\n",
      "Training Loss : 0.6903930918499828\tValidation Loss : 0.7450233189761639\n",
      "Validation loss decreased from : 0.7478326243162156 ----> 0.7450233189761639 ----> Saving Model.......\n",
      "Training Accuracy : 54.88657142857143\tValidation Accuracy : 13.699047619047619\n",
      "\n",
      "\n",
      "Epoch : 22\n",
      "Training Loss : 0.6721828268468379\tValidation Loss : 0.7778595726191998\n",
      "Training Accuracy : 55.18418181818182\tValidation Accuracy : 13.744545454545454\n",
      "\n",
      "\n",
      "Epoch : 23\n",
      "Training Loss : 0.6672453683614731\tValidation Loss : 0.7386179082095623\n",
      "Validation loss decreased from : 0.7450233189761639 ----> 0.7386179082095623 ----> Saving Model.......\n",
      "Training Accuracy : 55.454\tValidation Accuracy : 13.793565217391304\n",
      "\n",
      "\n",
      "Epoch : 24\n",
      "Training Loss : 0.6598656445741653\tValidation Loss : 0.7490642599761486\n",
      "Training Accuracy : 55.709833333333336\tValidation Accuracy : 13.834833333333334\n",
      "\n",
      "\n",
      "Epoch : 25\n",
      "Training Loss : 0.6470644877478481\tValidation Loss : 0.7705662310123443\n",
      "Training Accuracy : 55.96264\tValidation Accuracy : 13.87232\n",
      "\n",
      "\n",
      "Epoch : 26\n",
      "Training Loss : 0.6447447040118277\tValidation Loss : 0.7424013051390648\n",
      "Training Accuracy : 56.19576923076923\tValidation Accuracy : 13.911923076923078\n",
      "\n",
      "\n",
      "Epoch : 27\n",
      "Training Loss : 0.6336254451796413\tValidation Loss : 0.7409085932374001\n",
      "Training Accuracy : 56.423037037037034\tValidation Accuracy : 13.947037037037036\n",
      "\n",
      "\n",
      "Epoch : 28\n",
      "Training Loss : 0.6315064294822514\tValidation Loss : 0.7393822053074837\n",
      "Training Accuracy : 56.64342857142857\tValidation Accuracy : 13.982928571428571\n",
      "\n",
      "\n",
      "Epoch : 29\n",
      "Training Loss : 0.623722990527749\tValidation Loss : 0.7382628677785397\n",
      "Validation loss decreased from : 0.7386179082095623 ----> 0.7382628677785397 ----> Saving Model.......\n",
      "Training Accuracy : 56.84358620689655\tValidation Accuracy : 14.015172413793103\n",
      "\n",
      "\n",
      "Epoch : 30\n",
      "Training Loss : 0.6196301176771521\tValidation Loss : 0.7417624796926975\n",
      "Training Accuracy : 57.0344\tValidation Accuracy : 14.045266666666667\n",
      "\n",
      "\n",
      "Epoch : 31\n",
      "Training Loss : 0.6042194595560432\tValidation Loss : 0.7056269843876362\n",
      "Validation loss decreased from : 0.7382628677785397 ----> 0.7056269843876362 ----> Saving Model.......\n",
      "Training Accuracy : 57.22916129032258\tValidation Accuracy : 14.080645161290322\n",
      "\n",
      "\n",
      "Epoch : 32\n",
      "Training Loss : 0.608385212291032\tValidation Loss : 0.7211237490177155\n",
      "Training Accuracy : 57.4081875\tValidation Accuracy : 14.1121875\n",
      "\n",
      "\n",
      "Epoch : 33\n",
      "Training Loss : 0.597001433596015\tValidation Loss : 0.7001479667425156\n",
      "Validation loss decreased from : 0.7056269843876362 ----> 0.7001479667425156 ----> Saving Model.......\n",
      "Training Accuracy : 57.592060606060606\tValidation Accuracy : 14.143757575757576\n",
      "\n",
      "\n",
      "Epoch : 34\n",
      "Training Loss : 0.5920079843886197\tValidation Loss : 0.7171315939724445\n",
      "Training Accuracy : 57.76605882352941\tValidation Accuracy : 14.17135294117647\n",
      "\n",
      "\n",
      "Epoch : 35\n",
      "Training Loss : 0.5918023941665888\tValidation Loss : 0.7341950777173042\n",
      "Training Accuracy : 57.92948571428571\tValidation Accuracy : 14.196057142857143\n",
      "\n",
      "\n",
      "Epoch : 36\n",
      "Training Loss : 0.5816341308690608\tValidation Loss : 0.7289695708453655\n",
      "Training Accuracy : 58.093333333333334\tValidation Accuracy : 14.220333333333333\n",
      "\n",
      "\n",
      "Epoch : 37\n",
      "Training Loss : 0.5748873111605645\tValidation Loss : 0.7213339814543724\n",
      "Training Accuracy : 58.253837837837835\tValidation Accuracy : 14.24227027027027\n",
      "\n",
      "\n",
      "Epoch : 38\n",
      "Training Loss : 0.5713863483257592\tValidation Loss : 0.7141613486409187\n",
      "Training Accuracy : 58.40284210526316\tValidation Accuracy : 14.26921052631579\n",
      "\n",
      "\n",
      "Epoch : 39\n",
      "Training Loss : 0.5619090648368001\tValidation Loss : 0.6945221392810345\n",
      "Validation loss decreased from : 0.7001479667425156 ----> 0.6945221392810345 ----> Saving Model.......\n",
      "Training Accuracy : 58.557641025641026\tValidation Accuracy : 14.295435897435897\n",
      "\n",
      "\n",
      "Epoch : 40\n",
      "Training Loss : 0.55985431490466\tValidation Loss : 0.7278023780882359\n",
      "Training Accuracy : 58.69755\tValidation Accuracy : 14.3176\n",
      "\n",
      "\n",
      "Epoch : 41\n",
      "Training Loss : 0.554201921466738\tValidation Loss : 0.7278469568490982\n",
      "Training Accuracy : 58.84092682926829\tValidation Accuracy : 14.33819512195122\n",
      "\n",
      "\n",
      "Epoch : 42\n",
      "Training Loss : 0.549041161108762\tValidation Loss : 0.6967875362932682\n",
      "Training Accuracy : 58.97904761904762\tValidation Accuracy : 14.358904761904762\n",
      "\n",
      "\n",
      "Epoch : 43\n",
      "Training Loss : 0.5479964856058359\tValidation Loss : 0.7276729057729244\n",
      "Training Accuracy : 59.11293023255814\tValidation Accuracy : 14.377302325581395\n",
      "\n",
      "\n",
      "Epoch : 44\n",
      "Training Loss : 0.5408582537062466\tValidation Loss : 0.6965348236262798\n",
      "Training Accuracy : 59.24345454545455\tValidation Accuracy : 14.398909090909092\n",
      "\n",
      "\n",
      "Epoch : 45\n",
      "Training Loss : 0.5353445047140122\tValidation Loss : 0.7145487794280052\n",
      "Training Accuracy : 59.37008888888889\tValidation Accuracy : 14.417777777777777\n",
      "\n",
      "\n",
      "Epoch : 46\n",
      "Training Loss : 0.5298805009573698\tValidation Loss : 0.7111233817040921\n",
      "Training Accuracy : 59.4954347826087\tValidation Accuracy : 14.436173913043477\n",
      "\n",
      "\n",
      "Epoch : 47\n",
      "Training Loss : 0.5319861712306738\tValidation Loss : 0.7317304909229279\n",
      "Training Accuracy : 59.61617021276596\tValidation Accuracy : 14.45131914893617\n",
      "\n",
      "\n",
      "Epoch : 48\n",
      "Training Loss : 0.5285181376151741\tValidation Loss : 0.6882310132682323\n",
      "Validation loss decreased from : 0.6945221392810345 ----> 0.6882310132682323 ----> Saving Model.......\n",
      "Training Accuracy : 59.73683333333334\tValidation Accuracy : 14.470916666666668\n",
      "\n",
      "\n",
      "Epoch : 49\n",
      "Training Loss : 0.5188207375071943\tValidation Loss : 0.7019083268940449\n",
      "Training Accuracy : 59.851346938775514\tValidation Accuracy : 14.488081632653062\n",
      "\n",
      "\n",
      "Epoch : 50\n",
      "Training Loss : 0.5207569055818021\tValidation Loss : 0.7153779250383377\n",
      "Training Accuracy : 59.96252\tValidation Accuracy : 14.50456\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m2_loss,m2_acc=trainNet(model_2,0.01,train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142474"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of model parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make the model size comparable to the normal CIRFAR10 withou grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convNet,self).__init__()\n",
    "        self.conv1=Group_Conv(3,32,3,sub_size=3,padding=1,device=device)\n",
    "        self.conv2=Group_Conv(32,128,3,sub_size=8,padding=1,device=device)\n",
    "        self.conv3=Group_Conv(128,256,3,sub_size=8,padding=1,device=device)\n",
    "        self.conv4=Group_Conv(256,512,3,sub_size=16,padding=1,device=device)\n",
    "        self.conv5=Group_Conv(512,512,3,sub_size=16,padding=1,device=device)\n",
    "        self.b1=nn.BatchNorm2d(32)\n",
    "        self.b2=nn.BatchNorm2d(256)\n",
    "        self.b3=nn.BatchNorm2d(512)\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2,stride=2)  \n",
    "\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "        self.fc1=nn.Linear(512,256)\n",
    "        self.fc2=nn.Linear(256,128)\n",
    "        self.fc3=nn.Linear(128,64)\n",
    "        self.out=nn.Linear(64,10)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.b1(self.conv1(x))))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(F.relu(self.b2(self.conv3(x))))\n",
    "        x=self.pool(F.relu(self.conv4(x)))\n",
    "        x=self.pool(F.relu(self.b3(self.conv5(x))))\n",
    "        x=x.view(-1,512)\n",
    "        x = self.dropout(x)\n",
    "        x=self.dropout(F.relu(self.fc1(x)))\n",
    "        x=self.dropout(F.relu(self.fc2(x)))\n",
    "        x=self.dropout(F.relu(self.fc3(x)))\n",
    "        x=self.out(x)   \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convNet(\n",
      "  (conv1): Group_Conv()\n",
      "  (conv2): Group_Conv()\n",
      "  (conv3): Group_Conv()\n",
      "  (conv4): Group_Conv()\n",
      "  (conv5): Group_Conv()\n",
      "  (b1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ") \n",
      " On GPU :  True\n"
     ]
    }
   ],
   "source": [
    "def weight_init_normal(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find('Linear')!=-1:\n",
    "        n = m.in_features\n",
    "        y = (1.0/np.sqrt(n))\n",
    "        m.weight.data.normal_(0, y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "model_2=convNet()\n",
    "use_cuda=True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    model_2.cuda()\n",
    "print(model_2,'\\n','On GPU : ',use_cuda and torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352138"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of model parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNet(model,lr,trainer,validater):\n",
    "    optimizer=torch.optim.SGD(model.parameters(),lr=lr,momentum=0.9)\n",
    "\n",
    "\n",
    "    # Number of epochs to train for\n",
    "    loss_keeper={'train':[],'valid':[]}\n",
    "    acc_keeper={'train':[],'valid':[]}\n",
    "    train_class_correct = list(0. for i in range(10))\n",
    "    valid_class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    epochs=50\n",
    "\n",
    "    # minimum validation loss ----- set initial minimum to infinity\n",
    "    valid_loss_min = np.Inf \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss=0.0\n",
    "        valid_loss=0.0\n",
    "        train_correct=0.0\n",
    "        valid_correct=0.0\n",
    "        \"\"\"\n",
    "        TRAINING PHASE\n",
    "        \"\"\"\n",
    "        model.train() # TURN ON DROPOUT for training\n",
    "        for images,labels in trainer:\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                images,labels=images.cuda(),labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output=model(images)\n",
    "            loss=criterion(output,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "            _, pred = torch.max(output, 1)\n",
    "            train_correct=np.squeeze(pred.eq(labels.data.view_as(pred)))\n",
    "            for idx in range(batch_size):\n",
    "                label = labels[idx]\n",
    "                train_class_correct[label] += train_correct[idx].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "        \"\"\"\n",
    "        VALIDATION PHASE\n",
    "        \"\"\"\n",
    "        model.eval() # TURN OFF DROPOUT for validation\n",
    "        for images,labels in validater:\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                images,labels=images.cuda(),labels.cuda()\n",
    "            output=model(images)\n",
    "            loss=criterion(output,labels)\n",
    "            valid_loss+=loss.item()\n",
    "            _, pred = torch.max(output, 1)\n",
    "            valid_correct=np.squeeze(pred.eq(labels.data.view_as(pred)))\n",
    "            for idx in range(batch_size):\n",
    "                label = labels[idx]\n",
    "                valid_class_correct[label] += valid_correct[idx].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "        # Calculating loss over entire batch size for every epoch\n",
    "        train_loss = train_loss/len(trainer)\n",
    "        valid_loss = valid_loss/len(validater)\n",
    "\n",
    "        # Calculating loss over entire batch size for every epoch\n",
    "        train_acc=float(100. * np.sum(train_class_correct) / np.sum(class_total))\n",
    "        valid_acc=float(100. * np.sum(valid_class_correct) / np.sum(class_total))\n",
    "\n",
    "        # saving loss values\n",
    "        loss_keeper['train'].append(train_loss)\n",
    "        loss_keeper['valid'].append(valid_loss)\n",
    "\n",
    "        # saving acc values\n",
    "        acc_keeper['train'].append(train_acc)\n",
    "        acc_keeper['valid'].append(valid_acc)\n",
    "\n",
    "        print(f\"Epoch : {epoch+1}\")\n",
    "        print(f\"Training Loss : {train_loss}\\tValidation Loss : {valid_loss}\")\n",
    "\n",
    "        if valid_loss<=valid_loss_min:\n",
    "            print(f\"Validation loss decreased from : {valid_loss_min} ----> {valid_loss} ----> Saving Model.......\")\n",
    "            z=type(model).__name__\n",
    "            torch.save(model.state_dict(), z+'_model.pth')\n",
    "            valid_loss_min=valid_loss\n",
    "\n",
    "        print(f\"Training Accuracy : {train_acc}\\tValidation Accuracy : {valid_acc}\\n\\n\")\n",
    "\n",
    "    return(loss_keeper,acc_keeper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Training Loss : 1.667128021866083\tValidation Loss : 1.322991070151329\n",
      "Validation loss decreased from : inf ----> 1.322991070151329 ----> Saving Model.......\n",
      "Training Accuracy : 29.502\tValidation Accuracy : 10.164\n",
      "\n",
      "\n",
      "Epoch : 2\n",
      "Training Loss : 1.280290937870741\tValidation Loss : 1.2583829414844514\n",
      "Validation loss decreased from : 1.322991070151329 ----> 1.2583829414844514 ----> Saving Model.......\n",
      "Training Accuracy : 36.064\tValidation Accuracy : 10.671\n",
      "\n",
      "\n",
      "Epoch : 3\n",
      "Training Loss : 1.1327870928496122\tValidation Loss : 1.0980027213692665\n",
      "Validation loss decreased from : 1.2583829414844514 ----> 1.0980027213692665 ----> Saving Model.......\n",
      "Training Accuracy : 40.038\tValidation Accuracy : 11.205333333333334\n",
      "\n",
      "\n",
      "Epoch : 4\n",
      "Training Loss : 1.0378684470802546\tValidation Loss : 0.9833391413092614\n",
      "Validation loss decreased from : 1.0980027213692665 ----> 0.9833391413092614 ----> Saving Model.......\n",
      "Training Accuracy : 42.671\tValidation Accuracy : 11.678\n",
      "\n",
      "\n",
      "Epoch : 5\n",
      "Training Loss : 0.967954040914774\tValidation Loss : 0.9837812292575836\n",
      "Training Accuracy : 44.7168\tValidation Accuracy : 11.96\n",
      "\n",
      "\n",
      "Epoch : 6\n",
      "Training Loss : 0.9075723501294851\tValidation Loss : 0.8746978190541267\n",
      "Validation loss decreased from : 0.9833391413092614 ----> 0.8746978190541267 ----> Saving Model.......\n",
      "Training Accuracy : 46.364666666666665\tValidation Accuracy : 12.271333333333333\n",
      "\n",
      "\n",
      "Epoch : 7\n",
      "Training Loss : 0.867153396718204\tValidation Loss : 0.8380913008749485\n",
      "Validation loss decreased from : 0.8746978190541267 ----> 0.8380913008749485 ----> Saving Model.......\n",
      "Training Accuracy : 47.721714285714285\tValidation Accuracy : 12.535714285714286\n",
      "\n",
      "\n",
      "Epoch : 8\n",
      "Training Loss : 0.8292525206878781\tValidation Loss : 0.8133700796961785\n",
      "Validation loss decreased from : 0.8380913008749485 ----> 0.8133700796961785 ----> Saving Model.......\n",
      "Training Accuracy : 48.89675\tValidation Accuracy : 12.75825\n",
      "\n",
      "\n",
      "Epoch : 9\n",
      "Training Loss : 0.7985353624075651\tValidation Loss : 0.8104852229356766\n",
      "Validation loss decreased from : 0.8133700796961785 ----> 0.8104852229356766 ----> Saving Model.......\n",
      "Training Accuracy : 49.89533333333333\tValidation Accuracy : 12.932\n",
      "\n",
      "\n",
      "Epoch : 10\n",
      "Training Loss : 0.771068246141076\tValidation Loss : 0.7835571733117104\n",
      "Validation loss decreased from : 0.8104852229356766 ----> 0.7835571733117104 ----> Saving Model.......\n",
      "Training Accuracy : 50.7814\tValidation Accuracy : 13.0866\n",
      "\n",
      "\n",
      "Epoch : 11\n",
      "Training Loss : 0.7482146964594721\tValidation Loss : 0.7844911812245846\n",
      "Training Accuracy : 51.577636363636366\tValidation Accuracy : 13.22\n",
      "\n",
      "\n",
      "Epoch : 12\n",
      "Training Loss : 0.7227554139494896\tValidation Loss : 0.7061322416365147\n",
      "Validation loss decreased from : 0.7835571733117104 ----> 0.7061322416365147 ----> Saving Model.......\n",
      "Training Accuracy : 52.2705\tValidation Accuracy : 13.382\n",
      "\n",
      "\n",
      "Epoch : 13\n",
      "Training Loss : 0.7066811937093734\tValidation Loss : 0.7593291775882244\n",
      "Training Accuracy : 52.88076923076923\tValidation Accuracy : 13.490153846153847\n",
      "\n",
      "\n",
      "Epoch : 14\n",
      "Training Loss : 0.6867349979281425\tValidation Loss : 0.7239493589103222\n",
      "Training Accuracy : 53.46114285714286\tValidation Accuracy : 13.596857142857143\n",
      "\n",
      "\n",
      "Epoch : 15\n",
      "Training Loss : 0.6649223387986422\tValidation Loss : 0.7223525273799897\n",
      "Training Accuracy : 54.0144\tValidation Accuracy : 13.694\n",
      "\n",
      "\n",
      "Epoch : 16\n",
      "Training Loss : 0.6580301671475172\tValidation Loss : 0.7171183142066002\n",
      "Training Accuracy : 54.502625\tValidation Accuracy : 13.779375\n",
      "\n",
      "\n",
      "Epoch : 17\n",
      "Training Loss : 0.6367970150895417\tValidation Loss : 0.7040924972295761\n",
      "Validation loss decreased from : 0.7061322416365147 ----> 0.7040924972295761 ----> Saving Model.......\n",
      "Training Accuracy : 54.96964705882353\tValidation Accuracy : 13.856352941176471\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m2_loss,m2_acc\u001b[38;5;241m=\u001b[39m\u001b[43mtrainNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_2\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 33\u001b[0m, in \u001b[0;36mtrainNet\u001b[1;34m(model, lr, trainer, validater)\u001b[0m\n\u001b[0;32m     31\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 33\u001b[0m train_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m _, pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m train_correct\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqueeze(pred\u001b[38;5;241m.\u001b[39meq(labels\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mview_as(pred)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m2_loss,m2_acc=trainNet(model_2,0.01,train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cifar10.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "020910d477cc485eab87891ed80cd098": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0f7b0e50ddcb4f36a54d74c6f7178d16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2a29e0cdc684ab6b07a473184b16818",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7b0ac9d19ddc4c438e82bcae91983d90",
      "value": " 170500096/? [00:30&lt;00:00, 18436178.92it/s]"
     }
    },
    "23fd5f5cb146440ebc6d00dbedbd3bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7a363934b50404e821275e833e85d13",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_020910d477cc485eab87891ed80cd098",
      "value": 1
     }
    },
    "7255336faada45d6a1aaf77538d483e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b0ac9d19ddc4c438e82bcae91983d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2a29e0cdc684ab6b07a473184b16818": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7a363934b50404e821275e833e85d13": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a152f3d9ee4397b91c1d9d8880cce8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23fd5f5cb146440ebc6d00dbedbd3bcb",
       "IPY_MODEL_0f7b0e50ddcb4f36a54d74c6f7178d16"
      ],
      "layout": "IPY_MODEL_7255336faada45d6a1aaf77538d483e9"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
